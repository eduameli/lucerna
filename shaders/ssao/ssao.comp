#include "common.h"

struct ssao_pcs
{
#ifdef __cplusplus
  ssao_pcs()
    : inv_viewproj{1.0f}, kernelRadius{0.5} {}
#endif
  mat4_ar inv_viewproj;
  float kernelRadius;
};

struct u_ssao
{
  vec3_ar samples[64];
};

#ifndef __cplusplus

layout (local_size_x = 16, local_size_y = 17) in;

layout( push_constant ) uniform constants
{	
  ssao_pcs pcs;	
};

layout(set = 0, binding = 0) uniform sampler2D depthImage;
layout(r8, set = 0, binding = 1) uniform image2D outAmbient;

// no blue noise or whatever just testing if it works!
vec3 sampleKernel[8] = vec3[](
    vec3(0.1,  0.3,  0.2),
    vec3(-0.2, -0.3, 0.4),
    vec3(0.4,  -0.5, 0.1),
    vec3(-0.3, 0.1,  0.6),
    vec3(0.6,  -0.2, 0.3),
    vec3(-0.1, 0.5,  0.4),
    vec3(0.2,  -0.6, 0.1),
    vec3(-0.4, 0.2,  0.5)
);

// FIXME: temporary
float hash(vec2 p) {
    return fract(sin(dot(p ,vec2(127.1,311.7))) * 43758.5453123);
}

// Generate a random vec3 from screen position
vec3 randomVec3FromScreenPos(vec2 screenPos) {
    // Generate 3 random values based on screen position
    float r1 = hash(screenPos + vec2(1.0, 0.0));
    float r2 = hash(screenPos + vec2(0.0, 1.0));
    float r3 = hash(screenPos + vec2(1.0, 1.0));
    
    // Return as vec3
    return vec3(r1, r2, r3);
}

vec3 position_from_depth(vec2 uv, float depth, mat4 inv_viewproj)
{
  vec4 ndc = vec4(vec2(uv * 2.0 - 1.0), depth, 1.0);
  vec4 pos = inv_viewproj * ndc;
  return pos.xyz / pos.w;
}

float depth_from_position(vec3 position, mat4 viewproj)
{
  return 0.0;
}

// FIXME: wicked engine or other blogpost talk about improving this!.. now edges are broken
vec3 normal_from_depth(vec2 uv, mat4 inv_viewproj)
{

  vec2 depth_dimensions = vec2(1280, 800);

  vec2 uv0 = uv; // center
  vec2 uv1 = uv + vec2(1, 0) / depth_dimensions; // right 
  vec2 uv2 = uv + vec2(0, 1) / depth_dimensions; // top

  float depth0 = texture(depthImage, uv0).r;
  float depth1 = texture(depthImage, uv1).r;
  float depth2 = texture(depthImage, uv2).r;

  vec3 P0 = position_from_depth(uv0, depth0, inv_viewproj);
  vec3 P1 = position_from_depth(uv1, depth1, inv_viewproj);
  vec3 P2 = position_from_depth(uv2, depth2, inv_viewproj);

  return normalize(cross(P2 - P0, P1 - P0));
}

void main()
{
  ivec2 texelCoord = ivec2(gl_GlobalInvocationID.xy);
  ivec2 size = imageSize(outAmbient); // FIXME: put it in pcs
  
  // TODO: reconstruct depth without inv matrix? more optimised
  if (texelCoord.x < size.x && texelCoord.y < size.y)
  {
    vec2 texCoord = (vec2(texelCoord) + 0.5) / vec2(size);
    float depth = texture(depthImage, texCoord).r;
    vec3 normal = normal_from_depth(texCoord, pcs.inv_viewproj);

    vec3 position = position_from_depth(texCoord, depth, pcs.inv_viewproj);
    mat4 viewproj = inverse(pcs.inv_viewproj);
  

    vec3 randomVec = randomVec3FromScreenPos(vec2(texelCoord));
    vec3 tangent   = normalize(randomVec - normal * dot(randomVec, normal));
    vec3 bitangent = cross(normal, tangent);
    mat3 TBN       = mat3(tangent, bitangent, normal);  
    
    int oclussionFactor = 0;
    for (int i = 0; i < 8; i++)
    {
      vec4 p = vec4(position + (TBN*sampleKernel[i]) * pcs.kernelRadius, 1.0);
      vec4 uv = viewproj * p;
      vec3 uv_p = uv.xyz / uv.w;
      vec3 projCoords = uv_p * vec3(0.5, 0.5, 1.0) + vec3(0.5, 0.5, 0.0);
      oclussionFactor += texture(depthImage, projCoords.xy).r < depth ? 1 : 0; 
    }
    // select x points around current and if thei w uhh to be continued
    
    imageStore(outAmbient, texelCoord, vec4(float(oclussionFactor)/8.0, 0.0, 0.0, 0.0));
    //imageStore(outAmbient, texelCoord, vec4(n, 1.0));
  }
}

#endif
